---
layout: post
title: "Investigating the Impact of Unfairness Mitigation Techniques on Privacy Preserving Machine Learning"
date: 2021-09-29
tags: ML
---

*19th Nov 2021* - Edited note: I used the terms 'unfairness mitigation' and 'bias mitigation' interchangably in this report. I think the correct term should be 'unfairness mitigation'. In the paper [The Myth of Complete AI-Fairness](https://arxiv.org/pdf/2104.12544.pdf), Virginia Dignum makes the point that not all bias is bad, and bias in human data is impossible to fully eliminate. **"Bias is not the problem,"** they write, **"prejudice and discrimination are."**

> "Whereas prejudice represents a preconceived judgment or attitude, discrimination is a behaviour. In society, discrimination is often enacted through institutional structures and policies, and embedded in cultural beliefs and representations, and is thus reflected in any data collected. The focus need be on using AI to support interventions aimed at reducing prejudice and discrimination, e.g. through education, facilitation of intergroup contact, targeting social norms promoting positive relations between groups, or supporting people identify their own bias and prejudices."

<br/>

<iframe src="/assets/privacy_fairness_Report.pdf" width = "100%" height = "750px">
</iframe>
